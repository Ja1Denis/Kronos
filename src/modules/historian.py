import json
from src.modules.librarian import Librarian
from src.modules.oracle import Oracle
from src.utils.llm_client import LLMClient
from colorama import Fore, Style

class Historian:
    def __init__(self):
        self.librarian = Librarian()
        self.oracle = Oracle()
        self.llm = LLMClient()

    def find_contradictions(self, new_content: str, project: str = None):
        """
        Analizira novi sadrÅ¾aj i traÅ¾i kontradikcije s postojeÄ‡im znanjem.
        """
        print(f"ğŸ“œ Historian analizira konzistentnost za project={project}...")

        # 1. PronaÄ‘i relevantno postojeÄ‡e znanje
        # TraÅ¾imo odluke i Äinjenice koje su semantiÄki sliÄne
        results = self.oracle.ask(new_content, project=project, limit=5, silent=True)
        
        existing_entities = results.get('entities', [])
        
        # Filtriraj samo Decisions i Facts (case-insensitive)
        relevant_knowledge = [
            e for e in existing_entities 
            if e['type'].lower() in ['decision', 'fact']
        ]
        
        if not relevant_knowledge:
            return {
                "contradiction_found": False,
                "reasoning": "Nema relevantnog postojeÄ‡eg znanja za usporedbu."
            }

        # 2. Pripremi prompt za LLM
        knowledge_context = "\n".join([
            f"- [{e['type'].upper()} #{e['id']}] {e['content']}" 
            for e in relevant_knowledge
        ])

        prompt = f"""Ti si Historian, AI agent zaduÅ¾en za oÄuvanje konzistentnosti baze znanja.
Tvoj zadatak je detektirati kontradikcije izmeÄ‘u NOVOG unosa i POSTOJEÄ†EG znanja.

NOVI UNOS:
"{new_content}"

POSTOJEÄ†E ZNANJE (iz baze):
{knowledge_context}

ANALIZA:
1. Da li novi unos direktno ili indirektno proturjeÄi nekoj od navedenih postojeÄ‡ih informacija?
2. Ako da, koja toÄno informacija je u konfliktu (navedi ID)?
3. Koja je priroda konflikta (npr. promjena odluke, netoÄna Äinjenica, obratna logika)?

ODGOVOR (JSON format):
{{
    "contradiction_found": true/false,
    "conflicting_entity_ids": [id1, id2],
    "explanation": "Kratko objaÅ¡njenje konflikta...",
    "suggestion": "Sugestija Å¡to uÄiniti (npr. 'AÅ¾uriraj odluku #5' ili 'Odbaci novi unos')"
}}
Vrati SAMO JSON.
"""

        # 3. Pozovi LLM (koriÅ¡tenje stabilnog modela)
        response = self.llm.complete(prompt, model_name="gemini-2.0-flash")
        
        # 4. Parsiraj odgovor
        try:
            # Thinking modeli Äesto vraÄ‡aju puno teksta prije/poslije JSON-a
            clean_resp = response.strip()
            
            # TraÅ¾i prvi '{' i zadnji '}'
            start = clean_resp.find('{')
            end = clean_resp.rfind('}')
            
            if start != -1 and end != -1:
                json_str = clean_resp[start:end+1]
                analysis = json.loads(json_str)
                return analysis
            else:
                raise ValueError("Nije pronaÄ‘en validan JSON blok u odgovoru.")
            
        except Exception as e:
            print(f"âŒ GreÅ¡ka pri parsiranju Historian analize: {e}")
            print(f"ğŸ“„ Raw response preview: {response[:200]}...")
            return {
                "contradiction_found": False,
                "error": str(e)
            }

    def visualize_timeline(self, decision_id: int):
        """
        VraÄ‡a strukturirane podatke za vizualizaciju timeline-a odluke.
        """
        history = self.librarian.get_decision_history(decision_id)
        if not history:
            return None
            
        # Ovdje moÅ¾emo dodati dodatnu analizu ako treba
        return history
